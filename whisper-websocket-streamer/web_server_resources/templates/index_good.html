<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Realtime WebSocket Audio Streaming</title>
    <style>
        body {
            background-color: black;
            color: green;
        }
    </style>
</head>
<body>
    <h1>Realtime WebSocket Audio ddddStreaming</h1>
    <button id="startButton">Start Streaming</button>
    <button id="stopButton">Stop Streaming</button>
    <div id="responseContainer"></div>
    <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
    <script>








// Get access to the audio input (microphone)
navigator.mediaDevices.getUserMedia({audio: true}).then(stream => {
	// Create an AudioContext and MediaRecorder instances
	const context = new window.AudioContext();

	// Set up a WebSocket connection here...
	let socket;
	try{
		socket=new WebSocket("ws://"+window.location.host+"/asrstream")
	} catch(e){console.log('error:', e);}
	
	socket.onopen = () => {
		console.log('WebSocket connection opened');
	};

	socket.onclose = () => {
		console.log('WebSocket connection closed');
	};
	socket.onmessage = event => {
		console.log('WebSocket event',event);
		let responseContainer = document.getElementById('responseContainer');
		responseContainer.innerHTML += `<p>${event.data}</p>`;
	};
	socket.onerror = function(e) {console.log("socket ERROR",e)}
	
	const recorder =  new MediaRecorder(stream, {mimeType: 'audio/webm;codecs=pcm', audioBitrateMode:'constant', audioBitsPerSecond: 16000});
	recorder.onerror = function(e) {console.log("R ERROR",e)}
	recorder.onpause = function(e) {console.log("R pause",e)}
	recorder.onresume = function(e) {console.log("R resume",e)}
	recorder.onstart = function(e) {console.log("R start",e)}
	recorder.onstop = function(e) {console.log("R stop",e)}
	let chunks = [];

	recorder.ondataavailable = (event) => {
		//console.log('d', event, socket, WebSocket.OPEN);
		if (!socket || socket.readyState !== WebSocket.OPEN){console.log('CLOSED SOCK'); return;}
		const blobPartial = event.data; // This is a Blob representing the audio data for this chunk of recording.

<!--
		chunks.push(blobPartial); 
		// console.log('chunks',blobPartial)
		if (chunks.length > 0) { // You can adjust this to your liking, e.g., based on time or size...
-->
			const blob = new Blob([blobPartial], {'type': 'audio/wav'});  
			console.log('send',blob)
			socket.send(blob); 
			console.log('sent')
			chunks=[];//clear the chunk array for next set of data to be sent over websocket   
		}      
	};
	
	function startRecording() {
		console.log('start', recorder.state, socket);
		if (recorder.state !== 'recording') recorder.start(500);
	}
	
	function stopRecording() {
		console.log('stop', recorder.state, socket);
		if (recorder.state == 'recording')  recorder.stop()
	}
	
	
	document.getElementById('startButton').addEventListener('click', () => {
		startRecording();
	});

	document.getElementById('stopButton').addEventListener('click', () => {
		stopRecording();
	});
	
});



		
        //let ws = new WebSocket("ws://"+window.location.host+"/asrstream");
        //let mediaRecorder;

        //ws.onmessage = event => {
            //let responseContainer = document.getElementById('responseContainer');
            //responseContainer.innerHTML += `<p>${event}</p>`;
        //};

        //let handleDataAvailable = (event) => {
            //if (event.size > 0) {
                //console.log('blob', event)
                    //ws.send(event)

            //}
        //};

        //function blobToBase64(blob) {
            //return new Promise((resolve, reject) => {
                //const reader = new FileReader();
                //reader.readAsDataURL(blob);
                //reader.onload = () => {
                    //const base64String = reader.result.split(',')[1];
                    //resolve(base64String);
                //};
                //reader.onerror = (error) => reject(error);
            //});
        //}

        //navigator.mediaDevices.getUserMedia({ audio: true })
            //.then(stream => {
                //let recorder = RecordRTC(stream, {
                    //type: 'audio',
                    //recorderType: StereoAudioRecorder,
                    //mimeType: 'audio/wav',
                    //timeSlice: 500,
                    //desiredSampRate: 16000,
                    //numberOfAudioChannels: 1,
                    //ondataavailable: handleDataAvailable
                //});

                //document.getElementById('startButton').addEventListener('click', () => {
                    //recorder.startRecording();
                //});

                //document.getElementById('stopButton').addEventListener('click', () => {
                    //recorder.stopRecording();
                //});
            //});

        //ws.onopen = () => {
            //console.log('WebSocket connection opened');
        //};

        //ws.onclose = () => {
            //console.log('WebSocket connection closed');
        //};
    </script>
</body>
</html>

